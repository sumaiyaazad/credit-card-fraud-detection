epoch,Training accuracy,Training Loss,Validation accuracy,Validation Loss
1,99.7249596217317,0.324125232875548,99.9297777465679,0.31403806805610657
2,99.93992025779671,0.31390607588420033,99.9332888592395,0.3139303922653198
3,99.93874987320834,0.31388037294547455,99.9332888592395,0.3139196038246155
4,99.93914000140447,0.3138771266611964,99.9332888592395,0.3139505684375763
5,99.93914000140447,0.31387356577659425,99.9332888592395,0.31394124031066895
6,99.93992025779671,0.3138761445833434,99.9332888592395,0.3139113187789917
7,99.93992025779671,0.3138681565899778,99.9332888592395,0.31391939520835876
8,99.93992025779671,0.31386504037046,99.9332888592395,0.313917338848114
9,99.94070051418896,0.31386079413660783,99.9332888592395,0.3139251172542572
10,99.94070051418896,0.31386057067313244,99.9332888592395,0.3138962388038635
11,99.94070051418896,0.31385763158975,99.9332888592395,0.3139213025569916
12,99.93874987320834,0.31386649782344234,99.92626663389628,0.3139050006866455
13,99.94031038599283,0.3138614145278812,99.9332888592395,0.31392282247543335
14,99.94070051418896,0.31385940487815445,99.9332888592395,0.31389376521110535
15,99.94070051418896,0.31385736964106364,99.9332888592395,0.3139077425003052
16,99.94109064238509,0.3138573790159048,99.9332888592395,0.31392934918403625
17,99.94031038599283,0.3138618236578533,99.9332888592395,0.31392213702201843
18,99.94070051418896,0.3138542164764873,99.9332888592395,0.3139096796512604
19,99.94070051418896,0.31385937799988967,99.9332888592395,0.3139284551143646
20,99.94070051418896,0.3138630916869621,99.9332888592395,0.31392037868499756
