epoch,Training accuracy,Training Loss,Validation accuracy,Validation Loss
1,99.87359846445543,0.32292723430630094,99.9297777465679,0.3140321373939514
2,99.93953012960058,0.3139067936398953,99.92626663389628,0.3139696717262268
3,99.93953012960058,0.3138837816935177,99.9332888592395,0.3139253854751587
4,99.93992025779671,0.3138720320079407,99.92626663389628,0.3139519691467285
5,99.93992025779671,0.3138725980548968,99.9332888592395,0.31392213702201843
6,99.93992025779671,0.313868913984138,99.92626663389628,0.31393080949783325
7,99.93914000140447,0.3138644144770477,99.9332888592395,0.3139229416847229
8,99.94070051418896,0.3138586795519033,99.9332888592395,0.31391000747680664
9,99.94109064238509,0.31385531464612315,99.9332888592395,0.31392544507980347
10,99.94070051418896,0.31385726881687925,99.9332888592395,0.3139127194881439
11,99.94031038599283,0.31386917919541785,99.9332888592395,0.3139006495475769
12,99.94109064238509,0.3138617699050439,99.9332888592395,0.3138909339904785
13,99.94031038599283,0.31385639932268405,99.9332888592395,0.31391531229019165
14,99.94031038599283,0.3138585059610947,99.9332888592395,0.3139040470123291
15,99.93992025779671,0.3138553923903415,99.9332888592395,0.31390488147735596
16,99.94070051418896,0.3138530334459383,99.9332888592395,0.31390583515167236
17,99.94148077058121,0.31385633857222534,99.9332888592395,0.3138982653617859
18,99.94109064238509,0.3138590545529894,99.9332888592395,0.3139069378376007
19,99.94109064238509,0.31386281095883206,99.9367999719111,0.31390121579170227
20,99.94187089877734,0.31385276694375763,99.9332888592395,0.3138834238052368
